{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 文本转向量介绍\n",
    "\n",
    "\n",
    "#### 如何使用bert模型将文本转换成向量的\n",
    "1. 主要是使用hidden_status值、attention_mask 来做处理的。\n",
    "2. 基本的参考链接可以看这里 https://github.com/UKPLab/sentence-transformers/blob/06f5c4e9857f013da2657d43a77d9f5f0bf50a61/sentence_transformers/models/Pooling.py#L128\n",
    "3. 最常见的，或者最方便的，就是提取cls对应的hidden_status的值。当然，还有别的，这里先不展开介绍。\n",
    "\n",
    "\n",
    "#### 标准化问题\n",
    "1. 为什么有的时候是使用cos相似度，有的时候，就是直接用矩阵乘法\n",
    "2. 实际上是等效的：\n",
    "- 2.1 如果模型输出的时候，已经做过标准化了，那就直接使用矩阵乘法就行了。\n",
    "- 2.2 如果模型输出的时候，没有做标准化，那就使用cos相似度\n",
    "\n",
    "3. 做标准化部分，就相当于提前做了$A / ||A||$操作\n",
    "\n",
    "![](images/cos.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 如何使用文本转向量模型\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "model_name_or_path = \"model/bge-base-zh-v1.5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence embeddings: tensor([[-0.0157, -0.0291,  0.0919,  ..., -0.0066,  0.0219,  0.0269],\n",
      "        [-0.0168, -0.0304,  0.1028,  ..., -0.0277,  0.0120,  0.0091]])\n"
     ]
    }
   ],
   "source": [
    "# Sentences we want sentence embeddings for\n",
    "sentences = [\"样例数据-1\", \"样例数据-2\"]\n",
    "\n",
    "# Load model from HuggingFace Hub\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
    "model = AutoModel.from_pretrained(model_name_or_path)\n",
    "model.eval()\n",
    "\n",
    "# Tokenize sentences\n",
    "encoded_input = tokenizer(sentences, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "# for s2p(short query to long passage) retrieval task, add an instruction to query (not add instruction for passages)\n",
    "# encoded_input = tokenizer([instruction + q for q in queries], padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "# Compute token embeddings\n",
    "with torch.no_grad():\n",
    "    model_output = model(**encoded_input)\n",
    "    # Perform pooling. In this case, cls pooling.\n",
    "    sentence_embeddings = model_output[0][:, 0]\n",
    "# normalize embeddings\n",
    "sentence_embeddings = torch.nn.functional.normalize(sentence_embeddings, p=2, dim=1)\n",
    "print(\"Sentence embeddings:\", sentence_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### onnx 推理转换\n",
    "\n",
    "1. http://www.xavierdupre.fr/app/onnxcustom/helpsphinx/api/onnxruntime_python/helpers.html\n",
    "\n",
    "```BASH\n",
    "pip install \"optimum[onnxruntime]\" # cpu版本\n",
    "pip install \"optimum[onnxruntime-gpu]\" # gpu版本\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "import onnxruntime\n",
    "\n",
    "pprint.pprint(onnxruntime.get_available_providers())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['last_hidden_state', 'pooler_output'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 768])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output.last_hidden_state[:,0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch22",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
